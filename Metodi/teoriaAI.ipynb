{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c72e6c-3a41-460c-856a-7c48c0966600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domande di teoria sull‚Äôintelligenza artificiale\n",
    "#  ‚Ä¢ Intelligenza artificiale, Machine Learning e Deep Learning.‚Äì Intelligenza artificiale: Riproduzione parziale dell‚Äôattivit√† intellet\n",
    "# tuale propria dell‚Äôuomo (con particolare riguardo ai processi di ap\n",
    "# prendimento, di riconoscimento, di scelta) realizzata o attraverso\n",
    "#  l‚Äôelaborazione di modelli ideali, o, concretamente, con la messa a\n",
    "#  punto di macchine che utilizzano per lo pi√π a tale fine elaboratori\n",
    "#  elettronici.\n",
    "#  ‚àó L‚Äôintelligenza Artificiale forte riguarda sistemi che sono proget\n",
    "# tati per risolvere problemi specifici in un settore particolare.\n",
    "#  ‚àó L‚Äôintelligenza Artificiale debole riguarda sistemi che sono proget\n",
    "# tati per risolvere problemi generici.‚Äì Machine Learning: ‚ÄúIl Machine Learning √® quella branca\n",
    "#  dell‚Äôinformatica che permette a una macchina di imparare ad\n",
    "#  eseguire un compito senza essere esplicitamente programmata per\n",
    "#  farlo‚Äù- 1959 Herbert Simon‚Äì DeepLearning: odeepneural learning , √® un sottoinsieme del machine\n",
    "#  learning , che utilizza le reti neurali per analizzare diversi fattori con\n",
    "#  una struttura simile al sistema neurale umano.\n",
    "#  ‚Ä¢ Storia dell‚Äôintelligenza artificiale, Origini, I due Inverni, Tempi moderni:\n",
    "#  2011 ad oggi Deep Learning‚Äì La storia\n",
    "#  ‚Ä¢ Paradigma del machine Learning vs Paradigma di programmazione\n",
    "#  tradizionale.‚Äì ¬´Il Machine Learning √® il campo di studi che fornisce ai computer la\n",
    "#  capacit√† di imparare a risolvere i problemi senza essere esplicitamente\n",
    "#  programmati¬ª- Artur Samuel 1959. Prima era necessario istruire la\n",
    "#  macchina su come risolvere un specifico problema, mentre ora grazie\n",
    "#  al machine learning la macchina √® in grado di risolvere problemi di\n",
    "#  cui non √® stata istruita.\n",
    "#  ‚Ä¢ Preparazione dei dati (Training Set, Validation Set, Testing Set)‚Äì Modello‚Äì Predizione‚Äì Training Set: √® un insieme di dati utilizzati per addestrare un modello\n",
    "#  di machine learning. Il training set √® un sottoinsieme del dataset\n",
    "#  utilizzato per addestrare il modello.‚Äì Validation Set: su questi dati vengono messi a punto gli iperparametri\n",
    "#  del modello.‚Äì Testing Set: √® un insieme di dati utilizzati per valutare le prestazioni\n",
    "#  di un modello di machine learning.‚Äì Modello: √® il nucleo di un sistema di machine learning. √à il risul\n",
    "# tato dell‚Äôaddestramento del modello su un training set. Il modello\n",
    "#  rappresenta la conoscenza acquisita dal sistema di machine learning.‚Äì Predizione: √® il processo di utilizzo di un modello per effettuare pre\n",
    "# visioni su dati sconosciuti.\n",
    "#  ‚Ä¢ Task del Machine Learning: Classificazione, Regressione e Clustering\n",
    "#  1\n",
    "# ‚Äì Classificazione: il concetto di classe √® correlato al concetto di\n",
    "#  etichetta. L‚Äôobiettivo √® quello di assegnare un‚Äôetichetta a un oggetto\n",
    "#  in base alle sue caratteristiche.‚Äì Regressione: viene utilizzata per modellare la relazione tra una vari\n",
    "# abile dipendente e una o pi√π variabili indipendenti, al fine di fare\n",
    "#  previsioni su nuovi dati.‚Äì Clustering: √® una tecnica di apprendimento non supervisionato che\n",
    "#  raggruppa gli oggetti in base alle loro caratteristiche.\n",
    "#  ‚Ä¢ Necessit√† di una fase di feature extraction nel Machine learning‚Äì √® la procedura di estrazione delle caratteristiche dai dati in modo da\n",
    "#  creare un nuovo e pi√π contenuto insieme di dati in grado di descrivere\n",
    "#  in modo pi√π efficace il problema che si vuole risolvere.\n",
    "#  ‚Ä¢ Deep Learning vs Machine Learning‚Äì Il machine learning √® un campo che si occupa dello sviluppo di al\n",
    "# goritmi che permettono ai computer di imparare dai dati e di fare\n",
    "#  previsioni o prendere decisioni senza essere esplicitamente program\n",
    "# mati. Questi algoritmi analizzano i dati di input e identificano i\n",
    "#  modelli o le relazioni in essi contenuti per fare previsioni o prendere\n",
    "#  decisioni.‚Äì Il deep learning √® una sottocategoria del machine learning che uti\n",
    "# lizza reti neurali artificiali profonde per l‚Äôapprendimento automatico\n",
    "#  delle caratteristiche dai dati. Queste reti neurali profonde sono com\n",
    "# poste da molti strati di neuroni artificiali e possono apprendere di\n",
    "# rettamente dai dati senza la necessit√† di estrarre manualmente le\n",
    "#  caratteristiche.‚Äì In sintesi, il deep learning √® un approccio pi√π avanzato in cui le\n",
    "#  reti neurali profonde possono imparare automaticamente le caratter\n",
    "# istiche dai dati, eliminando la necessit√† di una pre-elaborazione man\n",
    "# uale. Tuttavia, richiede una grande quantit√† di dati di addestramento\n",
    "#  e risorse computazionali per l‚Äôaddestramento.\n",
    "#  ‚Ä¢ Classificazione degli algoritmi di Machine Learning: Algoritmi Supervi\n",
    "# sionati (Regressione e classificazione), Algoritmi non supervisionati (Clus\n",
    "# tering ed Associazione), Apprendimento Semi-supervisionato, Apprendi\n",
    "# mento con rinforzo.‚Äì Supervisionato: √® un tipo di apprendimento nel quale vengono pre\n",
    "# sentati i dati di input e gli output che essi dovrebbe generare, con\n",
    "#  lo scopo di apprendere una regola generale in grado di mappare la\n",
    "#  relazione tra gli stessi.\n",
    "#  ‚àó Regressione: √® un tipo di apprendimento supervisionato che si\n",
    "#  occupa di predire un valore numerico continuo. In altre parole,\n",
    "#  si tratta di modellare una relazione tra le variabili di input e una\n",
    "#  variabile di output continua.\n",
    "#  ‚àó Classificazione: √® un tipo di apprendimento supervisionato che\n",
    "#  si occupa di predire un valore discreto.‚Äì Non supervisionato: √® un tipo di apprendimento nel quale non ven\n",
    "# gono presentati gli output attesi, ma il sistema deve essere in grado\n",
    "#  2\n",
    "# di trovare da solo la struttura dei dati. In questo modo si vanno a\n",
    "#  creare classi con dati pi√π utili per le analisi successive e permettendo\n",
    "#  si scoprire nuove informazioni nei dati che non erano state consider\n",
    "# ate.\n",
    "#  ‚àó Clustering: √® un tipo di apprendimento non supervisionato che si\n",
    "#  occupa di raggruppare gli oggetti in base alle loro caratteristiche.\n",
    "#  ‚àó Associazione: √® un tipo di apprendimento non supervisionato che\n",
    "#  si occupa di trovare le relazioni tra gli oggetti.‚Äì Semi-supervisionato: √® un tipo di apprendimento nel quale vengono\n",
    "#  presentati sia dati di input che gli output attesi, ma solo per una\n",
    "#  parte dei dati. Il sistema deve essere in grado di trovare da solo la\n",
    "#  struttura dei dati.‚Äì Rinforzo: √® un tipo di apprendimento nel quale il sistema deve im\n",
    "# parare a prendere decisioni in base alle interazioni con l‚Äôambiente. Il\n",
    "#  sistema riceve un feedback in base alle sue azioni e deve imparare a\n",
    "#  massimizzare il feedback ricevuto.\n",
    "#  ‚Ä¢ Reti Neurali Artificiali: Neurone Biologico e Neurone artificiale. Funzioni\n",
    "#  di attivazione. Percettrone a soglia e limiti.‚Äì Neurone Biologico: √® un tipo di cellula del sistema nervoso che √® in\n",
    "#  grado di ricevere, elaborare e trasmettere informazioni. I neuroni\n",
    "#  sono collegati tra loro tramite sinapsi. Quando un neurone riceve un\n",
    "#  segnale da altri neuroni, elabora le informazioni e trasmette il segnale\n",
    "#  ai neuroni collegati tramite sinapsi. E‚Äô composto da:\n",
    "#  ‚àó Dendriti: sono le estremit√† del neurone che ricevono i segnali da\n",
    "#  altri neuroni.\n",
    "#  ‚àó Corpocellulare: elabora i segnali ricevuti dai dendriti e trasmette\n",
    "#  il segnale ai neuroni collegati tramite sinapsi.\n",
    "#  ‚àó Assone: trasmette il segnale ai neuroni collegati tramite sinapsi.\n",
    "#  ‚àó Sinapsi: sono le connessioni tra i neuroni. Quando un neu\n",
    "# rone riceve un segnale da altri neuroni, elabora le informazioni e\n",
    "#  trasmette il segnale ai neuroni collegati tramite sinapsi.‚Äì Neurone artificiale: √® un modello matematico che si ispira al neurone\n",
    "#  biologico. E‚Äô composto da:\n",
    "#  ‚àó Input: sono i segnali in ingresso al neurone.\n",
    "#  ‚àó Pesi: sono i parametri che vengono utilizzati per modificare\n",
    "#  l‚Äôimportanza dei segnali in ingresso.\n",
    "#  ‚àó Funzione di attivazione: √® una funzione che viene utilizzata per\n",
    "#  calcolare l‚Äôoutput del neurone.\n",
    "#  ‚àó Output: √® il segnale in uscita dal neurone.‚Äì Funzioni di attivazione: serve per derminare se un neurone deve es\n",
    "# sere attivato o meno. Si tratta di una funzione non lineare che prende\n",
    "#  in input la somma pesata dei segnali in ingresso al neurone e restitu\n",
    "# isce un output.‚Äì Percettrone a soglia: √® un modello matematico di neurone artificiale\n",
    "#  che prende in input un vettore di valori numerici e restituisce un\n",
    "#  output binario (0 o 1). Si tratta di una funzione non lineare che\n",
    "#  3\n",
    "# prende in input la somma pesata dei segnali in ingresso al neurone e\n",
    "#  restituisce un output.\n",
    "#  ‚àó Limiti del Percettrone a soglia: il percettrone a soglia non √® in\n",
    "#  grado di modellare funzioni non lineari. Per ovviare a questo\n",
    "#  problema sono state introdotte le reti neurali feedforward.\n",
    "#  ‚Ä¢ Reti Neurali artificiali: Input Layer, Hidden Layer, Output Layer. Reti\n",
    "#  FeedForward, Reti ricorrenti.‚Äì Una rete neurale artificiale √® costituita da neuroni artificiali collegati\n",
    "#  tr loro. Ogni connessione, come in un cervello biologico, pu√≤ trasmet\n",
    "# tere un segnale da un neurone all‚Äôaltro. I neuroni sono organizzati in\n",
    "#  strati. Ogni connessione ha un peso che determina l‚Äôimportanza del\n",
    "#  segnale trasmesso. Le reti neurali artificiali sono composte da gruppi\n",
    "#  di neuroni artificiali organizzati in strati:\n",
    "#  ‚àó Input Layer: √® lo strato di input della rete neurale. I neuroni di\n",
    "#  questo strato ricevono i dati in input alla rete neurale.\n",
    "#  ‚àó Hidden Layer: √® uno strato intermedio tra lo strato di input e\n",
    "#  lo strato di output. I neuroni di questo strato elaborano i dati\n",
    "#  ricevuti in input e trasmettono il segnale ai neuroni dello strato\n",
    "#  successivo.\n",
    "#  ‚àó Output Layer: √® lo strato di output della rete neurale. I neuroni\n",
    "#  di questo strato restituiscono il risultato della rete neurale.‚Äì Reti FeedForward: √® un tipo di rete neurale artificiale in cui i segnali\n",
    "#  si muovono in una sola direzione, dallo strato di input allo strato di\n",
    "#  output.‚Äì Reti ricorrenti: √® un tipo di rete neurale artificiale in cui i segnali si\n",
    "#  muovono in entrambe le direzioni, dallo strato di input allo strato di\n",
    "#  output e viceversa.\n",
    "#  ‚Ä¢ MultiLayer Preceptron (MLP)‚Äì E‚Äô un tipo di rete neurale artificiale feedforward in cui i neuroni sono\n",
    "#  organizzati in strati. Si tratta di uno dei modelli pi√π utilizzati per\n",
    "#  il deep learning. L‚ÄôMLP √® in grado di apprendere relazioni comp\n",
    "# lesse e non lineari tra i dati di input e l‚Äôoutput desiderato grazie\n",
    "#  alla sua struttura multistrato e alla capacit√† di modellare rappre\n",
    "# sentazioni gerarchiche dei dati. L‚Äôaddestramento dell‚ÄôMLP avviene\n",
    "#  utilizzando algoritmi di ottimizzazione come la retropropagazione\n",
    "#  dell‚Äôerrore, che calcola e aggiorna i pesi delle connessioni in base\n",
    "#  all‚Äôerrore tra l‚Äôoutput previsto e l‚Äôoutput desiderato. Il MLP pi√π co\n",
    "# mune √® l‚ÄôFFNN (FeedForward Neural Network), ed √® composto da:\n",
    "#  ‚àó un input Layer: √® lo strato di input della rete neurale. I neuroni\n",
    "#  di questo strato ricevono i dati in input alla rete neurale.\n",
    "#  ‚àó uno o pi√π Hidden Layer: √® uno strato intermedio tra lo strato di\n",
    "#  input e lo strato di output. I neuroni di questo strato elaborano\n",
    "#  i dati ricevuti in input e trasmettono il segnale ai neuroni dello\n",
    "#  strato successivo.\n",
    "#  ‚àó un output Layer: √® lo strato di output della rete neurale. I neu\n",
    "# roni di questo strato restituiscono il risultato della rete neurale.\n",
    "#  4\n",
    "# ‚Ä¢ Training di una rete neurale. Forward Propagagation e Backward Propa\n",
    "# gation.‚Äì Training di una rete neurale: √® il processo di addestramento di una\n",
    "#  rete neurale artificiale. Iterativamente, la rete neurale viene esposta\n",
    "#  a un insieme di dati di addestramento e viene aggiornata in base\n",
    "#  all‚Äôerrore tra l‚Äôoutput previsto e l‚Äôoutput desiderato. L‚Äôobiettivo del\n",
    "#  training √® quello di ridurre l‚Äôerrore tra l‚Äôoutput previsto e l‚Äôoutput\n",
    "#  desiderato.\n",
    "#  ‚àó Forward Propagation: √® il processo di calcolo dell‚Äôoutput di una\n",
    "#  rete neurale artificiale. L‚Äôoutput di ogni neurone viene calcolato\n",
    "#  utilizzando la funzione di attivazione e i pesi delle connessioni.\n",
    "#  ‚àó Backward Propagation: √® il processo di aggiornamento dei pesi\n",
    "#  delle connessioni di una rete neurale artificiale. L‚Äôaggiornamento\n",
    "#  dei pesi delle connessioni avviene utilizzando l‚Äôalgoritmo di ot\n",
    "# timizzazione della retropropagazione dell‚Äôerrore.\n",
    "#  ‚Ä¢ Loss Function e Funzione costo.‚Äì Loss Function: √® una funzione che misura l‚Äôerrore tra l‚Äôoutput pre\n",
    "# visto e l‚Äôoutput desiderato. L‚Äôobiettivo del training di una rete neu\n",
    "# rale artificiale √® quello di ridurre l‚Äôerrore tra l‚Äôoutput previsto e\n",
    "#  l‚Äôoutput desiderato. La loss function viene utilizzata per calcolare\n",
    "#  l‚Äôerrore tra l‚Äôoutput previsto e l‚Äôoutput desiderato.‚Äì Funzione costo: √® una funzione che misura l‚Äôerrore tra l‚Äôoutput pre\n",
    "# visto e l‚Äôoutput desiderato. L‚Äôobiettivo del training di una rete neu\n",
    "# rale artificiale √® quello di ridurre l‚Äôerrore tra l‚Äôoutput previsto e\n",
    "#  l‚Äôoutput desiderato. La funzione costo viene utilizzata per calcolare\n",
    "#  l‚Äôerrore tra l‚Äôoutput previsto e l‚Äôoutput desiderato. La funzione costo\n",
    "#  viene calcolata come: ùê∂ = ‚àëùëõ\n",
    "#  ùëñ=1\n",
    "#  ùêø(ùë¶ùëñ, ÃÇ ùë¶ùëñ)\n",
    "#  ùëõ\n",
    "#  dove ùëõ √® il numero di esempi\n",
    "#  di addestramento, ùë¶ùëñ √® l‚Äôosservazione effettiva dell‚Äôesempio di training\n",
    "#  i-esimo, ÃÇ ùë¶ùëñ √® la previsione dell‚Äôesempio di training i-esimo.\n",
    "#  ‚Ä¢ Reti neurali Convoluzionali.‚Äì Le reti MLP mancano di invarianza per traslazione, il che significa\n",
    "#  che sono sensibili ai cambiamenti di posizione dei pixel all‚Äôinterno\n",
    "#  di un‚Äôimmagine. Le reti neurali convoluzionali (CNN) sono reti pro\n",
    "# fonde (deep) ispirate alle ricerche biologiche di Hubel e Wiesel du\n",
    "# rante lo studio del cervello dei gatti. Utilizzano due tipi di celle:\n",
    "#  ‚àó celle semplici : specializzate nella rilevazione di caratteristiche\n",
    "#  locali dell‚Äôinput visivo (feature extractor), (Convoluzioni)\n",
    "#  ‚àó celle complesse : specializzate nell‚Äôintegrazione (pooling) delle\n",
    "#  informazioni provenienti da diverse posizioni retinotopiche per\n",
    "#  formare una rappresentazione globale dell‚Äôinput visivo, preser\n",
    "# vando le caratteristiche invarianti per posizione\n",
    "#  ‚Ä¢ Architettura di una rete CNN: parte convoluzionee parte fully-connected‚Äì La parte convoluzionale consiste di strati convoluzionali seguite da\n",
    "#  funzioni di attivazione non lineare tipo(RELU) e di pooling. Questa\n",
    "#  parte costituisce il componente essenziale dell‚Äôestrazione di feature\n",
    "#  5\n",
    "# ‚Äì La parte fully-connected consiste in un‚Äôarchitettura di rete neurale\n",
    "#  completamente connessa. Questa parte esegue il compito di classifi\n",
    "# cazione in base all‚Äôinput dalla parte convoluzionale.\n",
    "#  ‚Ä¢ Sotto quali condizioni, il metodo di discesa del gradiente con passo fisso\n",
    "#  converge a un punto stazionario della funzione costo, che pu√≤ essere un\n",
    "#  minimo globale se la funzione √® convessa?‚Äì La discesa del gradiente trova il minimo globale se la funzione costo\n",
    "#  C √® convessa e se sono soddisfatte le seguenti condizioni:\n",
    "#  ‚àó Condizione di Lipschitz per il gradiente: deve esistere una\n",
    "#  costante tale che il gradiente della funzione costo sia limitato\n",
    "#  superiormente da tale costante. In altre parole, il gradiente\n",
    "#  della funzione costo non deve essere troppo grande.\n",
    "#  ‚àó Step size: il passo di discesa deve essere scelto in modo che sia\n",
    "#  sufficientemente piccolo da garantire che la funzione costo de\n",
    "# cresca in ogni iterazione. In altre parole, il passo di discesa non\n",
    "#  deve essere troppo grande. E‚Äô importante anche sapere che la\n",
    "#  scelta del passo n pu√≤ essere limitante in termini di efficienza e\n",
    "#  convergenza in problemi di grandi dimensioni.\n",
    "#  ‚Ä¢ Non convessit√† della funzione di costo.‚Äì Lafunzione costo di una rete neurale √® non convessa. Questo significa\n",
    "#  che la discesa del gradiente non trova il minimo globale. Tuttavia,\n",
    "#  la discesa del gradiente trova un minimo locale. In altre parole, la\n",
    "#  discesa del gradiente trova un minimo locale che potrebbe non essere\n",
    "#  il minimo globale. Per gestire la non convessit√† della funzione di\n",
    "#  costo, √® necessario eseguire pi√π volte la discesa del gradiente con\n",
    "#  diversi valori iniziali dei pesi.\n",
    "#  ‚Ä¢ Importanza del learning rate nei metodi di discesa.‚Äì Il learning rate √® un iperparametro che controlla la dimensione del\n",
    "#  passo di discesa del gradiente. Determina quanto velocemente o lenta\n",
    "# mente il modello si adatta ai dati. Esso determina la dimensione dei\n",
    "#  passi che vengono compiuti durante l‚Äôaggiornamento dei parametri\n",
    "#  del modello lungo il gradiente della funzione di costo. L‚Äôimportanza\n",
    "#  del learning rate risiede nel fatto che esso pu√≤ influenzare significa\n",
    "# tivamente la convergenza del metodo di discesa del gradiente e la\n",
    "#  qualit√† della soluzione ottenuta. Un learning rate troppo grande pu√≤\n",
    "#  causare oscillazioni o divergenza del processo di ottimizzazione, men\n",
    "# tre un learning rate troppo piccolo pu√≤ rallentare notevolmente la\n",
    "#  convergenza, richiedendo pi√π iterazioni per raggiungere una soluzione\n",
    "#  accettabile. Un learning rate adeguato √® essenziale per ottenere una\n",
    "#  convergenza stabile e rapida del metodo di discesa del gradiente. Un\n",
    "#  learning rate ottimale dipende dalla natura del problema, dalla forma\n",
    "#  della funzione di costo e dalla scala dei dati.\n",
    "#  ‚Ä¢ Exact line search.‚Äì Gli algoritmi di ottimizzazione unidimensionale per trovare la di\n",
    "# mensione del passo ottimale sono genericamnete chiamati exact line\n",
    "#  search.\n",
    "#  6\n",
    "# ‚Ä¢ Inexact line search rule , Armijo rule.‚Äì La regola di Armijo, o regola di Armijo-Goldstein, √® un criterio uti\n",
    "# lizzato nell‚Äôottimizzazione numerica per determinare la dimensione\n",
    "#  del passo (o step size) da utilizzare durante la ricerca lineare in\n",
    "#  una direzione di discesa all‚Äôinterno di un algoritmo di ottimizzazione.\n",
    "#  Questa regola garantisce una riduzione significativa della funzione\n",
    "#  costo durante l‚Äôottimizzazione, assicurando nel contempo una conver\n",
    "# genza adeguata dell‚Äôalgoritmo. La regola di Armijo si basa sul con\n",
    "# cetto di ‚Äúbacktracking‚Äù o retrotracciamento, che consiste nel ridurre\n",
    "#  gradualmente la dimensione del passo fino a trovare un valore che\n",
    "#  soddisfi determinate condizioni. L‚Äôobiettivo √® trovare un passo che\n",
    "#  garantisca una riduzione sufficiente del valore della funzione costo\n",
    "#  durante la ricerca lineare. Il processo inizia con un punto iniziale e\n",
    "#  riduce progressivamente la dimensione del passo, moltiplicandola per\n",
    "#  un parametro Ôøø compreso tra 0 e 1. Questo processo viene iterato\n",
    "#  f\n",
    "#  ino a quando non viene raggiunta una riduzione sufficiente nella fun\n",
    "# zione obiettivo, rispettando una specifica condizione di Armijo. La\n",
    "#  condizione di Armijo richiede che la riduzione della funzione costo sia\n",
    "#  proporzionale alla riduzione prevista calcolata in base al gradiente e\n",
    "#  al passo corrente. Questo criterio permette di trovare uno step size\n",
    "#  adeguato che assicura una significativa diminuzione della funzione\n",
    "#  costo. Utilizzando la regola di Armijo, √® possibile controllare la di\n",
    "# mensione del passo durante l‚Äôottimizzazione, bilanciando la velocit√†\n",
    "#  di convergenza con la riduzione della funzione costo. In questo modo,\n",
    "#  si pu√≤ garantire una progressione efficace verso la soluzione ottimale\n",
    "#  del problema di ottimizzazione.\n",
    "#  ‚Ä¢ Metodo di ottimizzazione del gradient descent con momento. Perch√® √®\n",
    "#  stato studiato e formula di aggiornamento dei pesi.‚Äì Il Gradient Descent aggiorna i parametri con: ùë§ùëò+1 = ùë§ùëò‚àíùúÇ‚àáùê∂(ùë§ùëò).\n",
    "#  La discesa del gradiente trova il minimo globale se la funzione costo\n",
    "#  C√®convessa e se sono soddisfatte le condizioni di Lipschitz per il gra\n",
    "# diente e lo step size. Questo metodo √® stato studiato per affrontare\n",
    "#  due problematiche comuni nell‚Äôottimizzazione: la lentezza della con\n",
    "# vergenza e la possibilit√† di rimanere bloccati in minimi locali. Il con\n",
    "# cetto chiave del metodo del gradiente con momento √® l‚Äôintroduzione di\n",
    "#  un termine di momento, che rappresenta l‚Äôaccumulo di informazioni\n",
    "#  sulle iterazioni precedenti per guidare l‚Äôaggiornamento dei pesi. Il mo\n",
    "# mento agisce come una sorta di ‚Äúinerzia‚Äù che accelera l‚Äôottimizzazione\n",
    "#  nella direzione in cui la discesa del gradiente √® costante e rallenta\n",
    "#  quando la direzione cambia bruscamente.\n",
    "#  ‚Ä¢ Iperparametri di una rete neurale.‚Äì Gli iperparametri sono parametri esterni al modello di machine learn\n",
    "# ing che devono essere impostati prima dell‚Äôavvio del processo di ad\n",
    "# destramento. A differenza dei parametri del modello, che vengono\n",
    "#  appresi durante il processo di addestramento stesso, gli iperparametri\n",
    "#  influenzano il comportamento del processo di addestramento e la con\n",
    "# 7\n",
    "# f\n",
    "#  igurazione del modello. Gli iperparametri devono essere scelti con\n",
    "#  cura, in quanto possono influenzare significativamente la qualit√† della\n",
    "#  soluzione ottenuta e la velocit√† di convergenza del processo di adde\n",
    "# stramento. Gli iperparametri di un modello di rete neurale includono:- numero di epoche di addestramento;- dimensione del batch di ad\n",
    "# destramento;- learning rate;- funzione di costo;- architettura della\n",
    "#  rete neurale (numero di layer, numero di neuroni per layer, tipo di\n",
    "#  layer);- funzione di attivazione dei neuroni;- regolarizzazione (early\n",
    "#  stopping, dropout, L1, L2);- ottimizzatore (Gradient Descent, SGD,\n",
    "#  Adam, Adagrad, RMSProp);- ecc.\n",
    "#  ‚Ä¢ learning rate scheduling: step decay, decadimento esponenziale, decadi\n",
    "# mento dipendente dal tempo.‚Äì Durante l‚Äôallenamento di un modello di machine learning, la\n",
    "#  regolazione del learning rate, o tasso di apprendimento, √® spesso\n",
    "#  altrettanto importante della scelta dell‚Äôottimizzatore. La selezione\n",
    "#  adeguata del learning rate pu√≤ influire sulla velocit√† e sulla qual\n",
    "# it√† della convergenza dell‚Äôalgoritmo di ottimizzazione. All‚Äôinizio\n",
    "#  dell‚Äôallenamento, un learning rate elevato √® auspicabile poich√© i pesi\n",
    "#  del modello sono lontani dai minimi. Un learning rate alto consente\n",
    "#  un rapido aggiornamento dei pesi, accelerando l‚Äôapprendimento\n",
    "#  iniziale.\n",
    "#  Tuttavia, nella fase finale dell‚Äôapprendimento, quando\n",
    "#  i pesi si avvicinano ai minimi, un learning rate basso √® pi√π ap\n",
    "# propriato. Riducendo gradualmente il learning rate, si aumenta\n",
    "#  la probabilit√† di raggiungere il minimo globale senza oscillazioni\n",
    "#  eccessive. La regolazione del learning rate richiede la considerazione\n",
    "#  di diversi aspetti. In primo luogo, √® importante selezionare una\n",
    "#  dimensione adeguata per il learning rate. Se il learning rate √® troppo\n",
    "#  grande, l‚Äôottimizzazione pu√≤ divergere, mentre se √® troppo piccolo,\n",
    "#  l‚Äôallenamento richieder√† molto tempo o si otterr√† un risultato subot\n",
    "# timale. Inoltre, √® importante considerare il tasso di decadimento del\n",
    "#  learning rate nel corso dell‚Äôallenamento. Se il learning rate rimane\n",
    "#  elevato per troppo tempo, si pu√≤ rimbalzare intorno al minimo\n",
    "#  senza raggiungerlo. Un decadimento graduale del learning rate pu√≤\n",
    "#  essere vantaggioso per raggiungere un compromesso tra la velocit√†\n",
    "#  di convergenza e la precisione del risultato finale.\n",
    "#  ‚Ä¢ Learning rate adattivo: Adagrad, RMSProp, Adadelta, Adam.‚Äì La regolazione del learning rate √® una sfida nell‚Äôottimizzazione dei\n",
    "#  modelli di machine learning, poich√© gli iperparametri devono essere\n",
    "#  definiti in anticipo e dipendono dal tipo di modello e problema. In\n",
    "# oltre, applicare lo stesso learning rate a tutti gli aggiornamenti dei\n",
    "#  pesi potrebbe non essere ottimale, specialmente quando si hanno dati\n",
    "#  sparsi e si desidera aggiornare i pesi in modo diverso. Per affrontare\n",
    "#  queste sfide, sono stati sviluppati quattro metodi rappresentativi che\n",
    "#  modificano in modo adattivo il learning rate:\n",
    "#  ‚àó Adagrad: Adagrad adatta il learning rate per ogni parametro\n",
    "#  del modello in base alla frequenza degli aggiornamenti prece\n",
    "# 8\n",
    "# denti. Ci√≤ significa che i parametri che vengono aggiornati pi√π fre\n",
    "# quentemente hanno un learning rate ridotto, mentre i parametri\n",
    "#  meno frequentemente aggiornati hanno un learning rate mag\n",
    "# giore. Questo approccio aiuta a gestire i problemi di sparsity\n",
    "#  dei dati.\n",
    "#  ‚àó RMSProp: RMSProp(RootMeanSquarePropagation) modifica\n",
    "#  il learning rate in base alla media mobile degli aggiornamenti\n",
    "#  precedenti dei gradienti. Questo metodo attenua l‚Äôimpatto dei\n",
    "#  gradienti di grandi dimensioni, consentendo una regolazione pi√π\n",
    "#  stabile del learning rate nel corso dell‚Äôallenamento.\n",
    "#  ‚àó Adadelta: Adadelta √® un‚Äôaltra tecnica che adatta il learning rate\n",
    "#  in base alla media mobile degli aggiornamenti dei gradienti prece\n",
    "# denti. Tuttavia, a differenza di RMSProp, Adadelta utilizza an\n",
    "# che una stima della varianza dei gradienti per regolare il learning\n",
    "#  rate. Questo approccio permette un aggiornamento pi√π stabile\n",
    "#  dei pesi nel corso dell‚Äôallenamento.\n",
    "#  ‚àó Adam: Adam (Adaptive Moment Estimation) combina le carat\n",
    "# teristiche di Adagrad e RMSProp. Utilizza la media mobile dei\n",
    "#  gradienti e la varianza per adattare il learning rate. Inoltre, in\n",
    "# corpora un termine di momento che tiene conto della storia degli\n",
    "#  aggiornamenti precedenti dei gradienti. Adam √® uno dei metodi\n",
    "#  pi√π utilizzati in pratica ed √® efficace in una vasta gamma di prob\n",
    "# lemi.\n",
    "#  ‚Ä¢ Altro‚Äì Il vantaggio di jacobi √® che si pu√≤ parallelizzare. Ma nel caso non si\n",
    "#  parallelizza risulta essere pi√π lento di gauss seidel\n",
    "#  9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
