{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c72e6c-3a41-460c-856a-7c48c0966600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domande di teoria sull’intelligenza artificiale\n",
    "#  • Intelligenza artificiale, Machine Learning e Deep Learning.– Intelligenza artificiale: Riproduzione parziale dell’attività intellet\n",
    "# tuale propria dell’uomo (con particolare riguardo ai processi di ap\n",
    "# prendimento, di riconoscimento, di scelta) realizzata o attraverso\n",
    "#  l’elaborazione di modelli ideali, o, concretamente, con la messa a\n",
    "#  punto di macchine che utilizzano per lo più a tale fine elaboratori\n",
    "#  elettronici.\n",
    "#  ∗ L’intelligenza Artificiale forte riguarda sistemi che sono proget\n",
    "# tati per risolvere problemi specifici in un settore particolare.\n",
    "#  ∗ L’intelligenza Artificiale debole riguarda sistemi che sono proget\n",
    "# tati per risolvere problemi generici.– Machine Learning: “Il Machine Learning è quella branca\n",
    "#  dell’informatica che permette a una macchina di imparare ad\n",
    "#  eseguire un compito senza essere esplicitamente programmata per\n",
    "#  farlo”- 1959 Herbert Simon– DeepLearning: odeepneural learning , è un sottoinsieme del machine\n",
    "#  learning , che utilizza le reti neurali per analizzare diversi fattori con\n",
    "#  una struttura simile al sistema neurale umano.\n",
    "#  • Storia dell’intelligenza artificiale, Origini, I due Inverni, Tempi moderni:\n",
    "#  2011 ad oggi Deep Learning– La storia\n",
    "#  • Paradigma del machine Learning vs Paradigma di programmazione\n",
    "#  tradizionale.– «Il Machine Learning è il campo di studi che fornisce ai computer la\n",
    "#  capacità di imparare a risolvere i problemi senza essere esplicitamente\n",
    "#  programmati»- Artur Samuel 1959. Prima era necessario istruire la\n",
    "#  macchina su come risolvere un specifico problema, mentre ora grazie\n",
    "#  al machine learning la macchina è in grado di risolvere problemi di\n",
    "#  cui non è stata istruita.\n",
    "#  • Preparazione dei dati (Training Set, Validation Set, Testing Set)– Modello– Predizione– Training Set: è un insieme di dati utilizzati per addestrare un modello\n",
    "#  di machine learning. Il training set è un sottoinsieme del dataset\n",
    "#  utilizzato per addestrare il modello.– Validation Set: su questi dati vengono messi a punto gli iperparametri\n",
    "#  del modello.– Testing Set: è un insieme di dati utilizzati per valutare le prestazioni\n",
    "#  di un modello di machine learning.– Modello: è il nucleo di un sistema di machine learning. È il risul\n",
    "# tato dell’addestramento del modello su un training set. Il modello\n",
    "#  rappresenta la conoscenza acquisita dal sistema di machine learning.– Predizione: è il processo di utilizzo di un modello per effettuare pre\n",
    "# visioni su dati sconosciuti.\n",
    "#  • Task del Machine Learning: Classificazione, Regressione e Clustering\n",
    "#  1\n",
    "# – Classificazione: il concetto di classe è correlato al concetto di\n",
    "#  etichetta. L’obiettivo è quello di assegnare un’etichetta a un oggetto\n",
    "#  in base alle sue caratteristiche.– Regressione: viene utilizzata per modellare la relazione tra una vari\n",
    "# abile dipendente e una o più variabili indipendenti, al fine di fare\n",
    "#  previsioni su nuovi dati.– Clustering: è una tecnica di apprendimento non supervisionato che\n",
    "#  raggruppa gli oggetti in base alle loro caratteristiche.\n",
    "#  • Necessità di una fase di feature extraction nel Machine learning– è la procedura di estrazione delle caratteristiche dai dati in modo da\n",
    "#  creare un nuovo e più contenuto insieme di dati in grado di descrivere\n",
    "#  in modo più efficace il problema che si vuole risolvere.\n",
    "#  • Deep Learning vs Machine Learning– Il machine learning è un campo che si occupa dello sviluppo di al\n",
    "# goritmi che permettono ai computer di imparare dai dati e di fare\n",
    "#  previsioni o prendere decisioni senza essere esplicitamente program\n",
    "# mati. Questi algoritmi analizzano i dati di input e identificano i\n",
    "#  modelli o le relazioni in essi contenuti per fare previsioni o prendere\n",
    "#  decisioni.– Il deep learning è una sottocategoria del machine learning che uti\n",
    "# lizza reti neurali artificiali profonde per l’apprendimento automatico\n",
    "#  delle caratteristiche dai dati. Queste reti neurali profonde sono com\n",
    "# poste da molti strati di neuroni artificiali e possono apprendere di\n",
    "# rettamente dai dati senza la necessità di estrarre manualmente le\n",
    "#  caratteristiche.– In sintesi, il deep learning è un approccio più avanzato in cui le\n",
    "#  reti neurali profonde possono imparare automaticamente le caratter\n",
    "# istiche dai dati, eliminando la necessità di una pre-elaborazione man\n",
    "# uale. Tuttavia, richiede una grande quantità di dati di addestramento\n",
    "#  e risorse computazionali per l’addestramento.\n",
    "#  • Classificazione degli algoritmi di Machine Learning: Algoritmi Supervi\n",
    "# sionati (Regressione e classificazione), Algoritmi non supervisionati (Clus\n",
    "# tering ed Associazione), Apprendimento Semi-supervisionato, Apprendi\n",
    "# mento con rinforzo.– Supervisionato: è un tipo di apprendimento nel quale vengono pre\n",
    "# sentati i dati di input e gli output che essi dovrebbe generare, con\n",
    "#  lo scopo di apprendere una regola generale in grado di mappare la\n",
    "#  relazione tra gli stessi.\n",
    "#  ∗ Regressione: è un tipo di apprendimento supervisionato che si\n",
    "#  occupa di predire un valore numerico continuo. In altre parole,\n",
    "#  si tratta di modellare una relazione tra le variabili di input e una\n",
    "#  variabile di output continua.\n",
    "#  ∗ Classificazione: è un tipo di apprendimento supervisionato che\n",
    "#  si occupa di predire un valore discreto.– Non supervisionato: è un tipo di apprendimento nel quale non ven\n",
    "# gono presentati gli output attesi, ma il sistema deve essere in grado\n",
    "#  2\n",
    "# di trovare da solo la struttura dei dati. In questo modo si vanno a\n",
    "#  creare classi con dati più utili per le analisi successive e permettendo\n",
    "#  si scoprire nuove informazioni nei dati che non erano state consider\n",
    "# ate.\n",
    "#  ∗ Clustering: è un tipo di apprendimento non supervisionato che si\n",
    "#  occupa di raggruppare gli oggetti in base alle loro caratteristiche.\n",
    "#  ∗ Associazione: è un tipo di apprendimento non supervisionato che\n",
    "#  si occupa di trovare le relazioni tra gli oggetti.– Semi-supervisionato: è un tipo di apprendimento nel quale vengono\n",
    "#  presentati sia dati di input che gli output attesi, ma solo per una\n",
    "#  parte dei dati. Il sistema deve essere in grado di trovare da solo la\n",
    "#  struttura dei dati.– Rinforzo: è un tipo di apprendimento nel quale il sistema deve im\n",
    "# parare a prendere decisioni in base alle interazioni con l’ambiente. Il\n",
    "#  sistema riceve un feedback in base alle sue azioni e deve imparare a\n",
    "#  massimizzare il feedback ricevuto.\n",
    "#  • Reti Neurali Artificiali: Neurone Biologico e Neurone artificiale. Funzioni\n",
    "#  di attivazione. Percettrone a soglia e limiti.– Neurone Biologico: è un tipo di cellula del sistema nervoso che è in\n",
    "#  grado di ricevere, elaborare e trasmettere informazioni. I neuroni\n",
    "#  sono collegati tra loro tramite sinapsi. Quando un neurone riceve un\n",
    "#  segnale da altri neuroni, elabora le informazioni e trasmette il segnale\n",
    "#  ai neuroni collegati tramite sinapsi. E’ composto da:\n",
    "#  ∗ Dendriti: sono le estremità del neurone che ricevono i segnali da\n",
    "#  altri neuroni.\n",
    "#  ∗ Corpocellulare: elabora i segnali ricevuti dai dendriti e trasmette\n",
    "#  il segnale ai neuroni collegati tramite sinapsi.\n",
    "#  ∗ Assone: trasmette il segnale ai neuroni collegati tramite sinapsi.\n",
    "#  ∗ Sinapsi: sono le connessioni tra i neuroni. Quando un neu\n",
    "# rone riceve un segnale da altri neuroni, elabora le informazioni e\n",
    "#  trasmette il segnale ai neuroni collegati tramite sinapsi.– Neurone artificiale: è un modello matematico che si ispira al neurone\n",
    "#  biologico. E’ composto da:\n",
    "#  ∗ Input: sono i segnali in ingresso al neurone.\n",
    "#  ∗ Pesi: sono i parametri che vengono utilizzati per modificare\n",
    "#  l’importanza dei segnali in ingresso.\n",
    "#  ∗ Funzione di attivazione: è una funzione che viene utilizzata per\n",
    "#  calcolare l’output del neurone.\n",
    "#  ∗ Output: è il segnale in uscita dal neurone.– Funzioni di attivazione: serve per derminare se un neurone deve es\n",
    "# sere attivato o meno. Si tratta di una funzione non lineare che prende\n",
    "#  in input la somma pesata dei segnali in ingresso al neurone e restitu\n",
    "# isce un output.– Percettrone a soglia: è un modello matematico di neurone artificiale\n",
    "#  che prende in input un vettore di valori numerici e restituisce un\n",
    "#  output binario (0 o 1). Si tratta di una funzione non lineare che\n",
    "#  3\n",
    "# prende in input la somma pesata dei segnali in ingresso al neurone e\n",
    "#  restituisce un output.\n",
    "#  ∗ Limiti del Percettrone a soglia: il percettrone a soglia non è in\n",
    "#  grado di modellare funzioni non lineari. Per ovviare a questo\n",
    "#  problema sono state introdotte le reti neurali feedforward.\n",
    "#  • Reti Neurali artificiali: Input Layer, Hidden Layer, Output Layer. Reti\n",
    "#  FeedForward, Reti ricorrenti.– Una rete neurale artificiale è costituita da neuroni artificiali collegati\n",
    "#  tr loro. Ogni connessione, come in un cervello biologico, può trasmet\n",
    "# tere un segnale da un neurone all’altro. I neuroni sono organizzati in\n",
    "#  strati. Ogni connessione ha un peso che determina l’importanza del\n",
    "#  segnale trasmesso. Le reti neurali artificiali sono composte da gruppi\n",
    "#  di neuroni artificiali organizzati in strati:\n",
    "#  ∗ Input Layer: è lo strato di input della rete neurale. I neuroni di\n",
    "#  questo strato ricevono i dati in input alla rete neurale.\n",
    "#  ∗ Hidden Layer: è uno strato intermedio tra lo strato di input e\n",
    "#  lo strato di output. I neuroni di questo strato elaborano i dati\n",
    "#  ricevuti in input e trasmettono il segnale ai neuroni dello strato\n",
    "#  successivo.\n",
    "#  ∗ Output Layer: è lo strato di output della rete neurale. I neuroni\n",
    "#  di questo strato restituiscono il risultato della rete neurale.– Reti FeedForward: è un tipo di rete neurale artificiale in cui i segnali\n",
    "#  si muovono in una sola direzione, dallo strato di input allo strato di\n",
    "#  output.– Reti ricorrenti: è un tipo di rete neurale artificiale in cui i segnali si\n",
    "#  muovono in entrambe le direzioni, dallo strato di input allo strato di\n",
    "#  output e viceversa.\n",
    "#  • MultiLayer Preceptron (MLP)– E’ un tipo di rete neurale artificiale feedforward in cui i neuroni sono\n",
    "#  organizzati in strati. Si tratta di uno dei modelli più utilizzati per\n",
    "#  il deep learning. L’MLP è in grado di apprendere relazioni comp\n",
    "# lesse e non lineari tra i dati di input e l’output desiderato grazie\n",
    "#  alla sua struttura multistrato e alla capacità di modellare rappre\n",
    "# sentazioni gerarchiche dei dati. L’addestramento dell’MLP avviene\n",
    "#  utilizzando algoritmi di ottimizzazione come la retropropagazione\n",
    "#  dell’errore, che calcola e aggiorna i pesi delle connessioni in base\n",
    "#  all’errore tra l’output previsto e l’output desiderato. Il MLP più co\n",
    "# mune è l’FFNN (FeedForward Neural Network), ed è composto da:\n",
    "#  ∗ un input Layer: è lo strato di input della rete neurale. I neuroni\n",
    "#  di questo strato ricevono i dati in input alla rete neurale.\n",
    "#  ∗ uno o più Hidden Layer: è uno strato intermedio tra lo strato di\n",
    "#  input e lo strato di output. I neuroni di questo strato elaborano\n",
    "#  i dati ricevuti in input e trasmettono il segnale ai neuroni dello\n",
    "#  strato successivo.\n",
    "#  ∗ un output Layer: è lo strato di output della rete neurale. I neu\n",
    "# roni di questo strato restituiscono il risultato della rete neurale.\n",
    "#  4\n",
    "# • Training di una rete neurale. Forward Propagagation e Backward Propa\n",
    "# gation.– Training di una rete neurale: è il processo di addestramento di una\n",
    "#  rete neurale artificiale. Iterativamente, la rete neurale viene esposta\n",
    "#  a un insieme di dati di addestramento e viene aggiornata in base\n",
    "#  all’errore tra l’output previsto e l’output desiderato. L’obiettivo del\n",
    "#  training è quello di ridurre l’errore tra l’output previsto e l’output\n",
    "#  desiderato.\n",
    "#  ∗ Forward Propagation: è il processo di calcolo dell’output di una\n",
    "#  rete neurale artificiale. L’output di ogni neurone viene calcolato\n",
    "#  utilizzando la funzione di attivazione e i pesi delle connessioni.\n",
    "#  ∗ Backward Propagation: è il processo di aggiornamento dei pesi\n",
    "#  delle connessioni di una rete neurale artificiale. L’aggiornamento\n",
    "#  dei pesi delle connessioni avviene utilizzando l’algoritmo di ot\n",
    "# timizzazione della retropropagazione dell’errore.\n",
    "#  • Loss Function e Funzione costo.– Loss Function: è una funzione che misura l’errore tra l’output pre\n",
    "# visto e l’output desiderato. L’obiettivo del training di una rete neu\n",
    "# rale artificiale è quello di ridurre l’errore tra l’output previsto e\n",
    "#  l’output desiderato. La loss function viene utilizzata per calcolare\n",
    "#  l’errore tra l’output previsto e l’output desiderato.– Funzione costo: è una funzione che misura l’errore tra l’output pre\n",
    "# visto e l’output desiderato. L’obiettivo del training di una rete neu\n",
    "# rale artificiale è quello di ridurre l’errore tra l’output previsto e\n",
    "#  l’output desiderato. La funzione costo viene utilizzata per calcolare\n",
    "#  l’errore tra l’output previsto e l’output desiderato. La funzione costo\n",
    "#  viene calcolata come: 𝐶 = ∑𝑛\n",
    "#  𝑖=1\n",
    "#  𝐿(𝑦𝑖, ̂ 𝑦𝑖)\n",
    "#  𝑛\n",
    "#  dove 𝑛 è il numero di esempi\n",
    "#  di addestramento, 𝑦𝑖 è l’osservazione effettiva dell’esempio di training\n",
    "#  i-esimo, ̂ 𝑦𝑖 è la previsione dell’esempio di training i-esimo.\n",
    "#  • Reti neurali Convoluzionali.– Le reti MLP mancano di invarianza per traslazione, il che significa\n",
    "#  che sono sensibili ai cambiamenti di posizione dei pixel all’interno\n",
    "#  di un’immagine. Le reti neurali convoluzionali (CNN) sono reti pro\n",
    "# fonde (deep) ispirate alle ricerche biologiche di Hubel e Wiesel du\n",
    "# rante lo studio del cervello dei gatti. Utilizzano due tipi di celle:\n",
    "#  ∗ celle semplici : specializzate nella rilevazione di caratteristiche\n",
    "#  locali dell’input visivo (feature extractor), (Convoluzioni)\n",
    "#  ∗ celle complesse : specializzate nell’integrazione (pooling) delle\n",
    "#  informazioni provenienti da diverse posizioni retinotopiche per\n",
    "#  formare una rappresentazione globale dell’input visivo, preser\n",
    "# vando le caratteristiche invarianti per posizione\n",
    "#  • Architettura di una rete CNN: parte convoluzionee parte fully-connected– La parte convoluzionale consiste di strati convoluzionali seguite da\n",
    "#  funzioni di attivazione non lineare tipo(RELU) e di pooling. Questa\n",
    "#  parte costituisce il componente essenziale dell’estrazione di feature\n",
    "#  5\n",
    "# – La parte fully-connected consiste in un’architettura di rete neurale\n",
    "#  completamente connessa. Questa parte esegue il compito di classifi\n",
    "# cazione in base all’input dalla parte convoluzionale.\n",
    "#  • Sotto quali condizioni, il metodo di discesa del gradiente con passo fisso\n",
    "#  converge a un punto stazionario della funzione costo, che può essere un\n",
    "#  minimo globale se la funzione è convessa?– La discesa del gradiente trova il minimo globale se la funzione costo\n",
    "#  C è convessa e se sono soddisfatte le seguenti condizioni:\n",
    "#  ∗ Condizione di Lipschitz per il gradiente: deve esistere una\n",
    "#  costante tale che il gradiente della funzione costo sia limitato\n",
    "#  superiormente da tale costante. In altre parole, il gradiente\n",
    "#  della funzione costo non deve essere troppo grande.\n",
    "#  ∗ Step size: il passo di discesa deve essere scelto in modo che sia\n",
    "#  sufficientemente piccolo da garantire che la funzione costo de\n",
    "# cresca in ogni iterazione. In altre parole, il passo di discesa non\n",
    "#  deve essere troppo grande. E’ importante anche sapere che la\n",
    "#  scelta del passo n può essere limitante in termini di efficienza e\n",
    "#  convergenza in problemi di grandi dimensioni.\n",
    "#  • Non convessità della funzione di costo.– Lafunzione costo di una rete neurale è non convessa. Questo significa\n",
    "#  che la discesa del gradiente non trova il minimo globale. Tuttavia,\n",
    "#  la discesa del gradiente trova un minimo locale. In altre parole, la\n",
    "#  discesa del gradiente trova un minimo locale che potrebbe non essere\n",
    "#  il minimo globale. Per gestire la non convessità della funzione di\n",
    "#  costo, è necessario eseguire più volte la discesa del gradiente con\n",
    "#  diversi valori iniziali dei pesi.\n",
    "#  • Importanza del learning rate nei metodi di discesa.– Il learning rate è un iperparametro che controlla la dimensione del\n",
    "#  passo di discesa del gradiente. Determina quanto velocemente o lenta\n",
    "# mente il modello si adatta ai dati. Esso determina la dimensione dei\n",
    "#  passi che vengono compiuti durante l’aggiornamento dei parametri\n",
    "#  del modello lungo il gradiente della funzione di costo. L’importanza\n",
    "#  del learning rate risiede nel fatto che esso può influenzare significa\n",
    "# tivamente la convergenza del metodo di discesa del gradiente e la\n",
    "#  qualità della soluzione ottenuta. Un learning rate troppo grande può\n",
    "#  causare oscillazioni o divergenza del processo di ottimizzazione, men\n",
    "# tre un learning rate troppo piccolo può rallentare notevolmente la\n",
    "#  convergenza, richiedendo più iterazioni per raggiungere una soluzione\n",
    "#  accettabile. Un learning rate adeguato è essenziale per ottenere una\n",
    "#  convergenza stabile e rapida del metodo di discesa del gradiente. Un\n",
    "#  learning rate ottimale dipende dalla natura del problema, dalla forma\n",
    "#  della funzione di costo e dalla scala dei dati.\n",
    "#  • Exact line search.– Gli algoritmi di ottimizzazione unidimensionale per trovare la di\n",
    "# mensione del passo ottimale sono genericamnete chiamati exact line\n",
    "#  search.\n",
    "#  6\n",
    "# • Inexact line search rule , Armijo rule.– La regola di Armijo, o regola di Armijo-Goldstein, è un criterio uti\n",
    "# lizzato nell’ottimizzazione numerica per determinare la dimensione\n",
    "#  del passo (o step size) da utilizzare durante la ricerca lineare in\n",
    "#  una direzione di discesa all’interno di un algoritmo di ottimizzazione.\n",
    "#  Questa regola garantisce una riduzione significativa della funzione\n",
    "#  costo durante l’ottimizzazione, assicurando nel contempo una conver\n",
    "# genza adeguata dell’algoritmo. La regola di Armijo si basa sul con\n",
    "# cetto di “backtracking” o retrotracciamento, che consiste nel ridurre\n",
    "#  gradualmente la dimensione del passo fino a trovare un valore che\n",
    "#  soddisfi determinate condizioni. L’obiettivo è trovare un passo che\n",
    "#  garantisca una riduzione sufficiente del valore della funzione costo\n",
    "#  durante la ricerca lineare. Il processo inizia con un punto iniziale e\n",
    "#  riduce progressivamente la dimensione del passo, moltiplicandola per\n",
    "#  un parametro ￿ compreso tra 0 e 1. Questo processo viene iterato\n",
    "#  f\n",
    "#  ino a quando non viene raggiunta una riduzione sufficiente nella fun\n",
    "# zione obiettivo, rispettando una specifica condizione di Armijo. La\n",
    "#  condizione di Armijo richiede che la riduzione della funzione costo sia\n",
    "#  proporzionale alla riduzione prevista calcolata in base al gradiente e\n",
    "#  al passo corrente. Questo criterio permette di trovare uno step size\n",
    "#  adeguato che assicura una significativa diminuzione della funzione\n",
    "#  costo. Utilizzando la regola di Armijo, è possibile controllare la di\n",
    "# mensione del passo durante l’ottimizzazione, bilanciando la velocità\n",
    "#  di convergenza con la riduzione della funzione costo. In questo modo,\n",
    "#  si può garantire una progressione efficace verso la soluzione ottimale\n",
    "#  del problema di ottimizzazione.\n",
    "#  • Metodo di ottimizzazione del gradient descent con momento. Perchè è\n",
    "#  stato studiato e formula di aggiornamento dei pesi.– Il Gradient Descent aggiorna i parametri con: 𝑤𝑘+1 = 𝑤𝑘−𝜂∇𝐶(𝑤𝑘).\n",
    "#  La discesa del gradiente trova il minimo globale se la funzione costo\n",
    "#  Cèconvessa e se sono soddisfatte le condizioni di Lipschitz per il gra\n",
    "# diente e lo step size. Questo metodo è stato studiato per affrontare\n",
    "#  due problematiche comuni nell’ottimizzazione: la lentezza della con\n",
    "# vergenza e la possibilità di rimanere bloccati in minimi locali. Il con\n",
    "# cetto chiave del metodo del gradiente con momento è l’introduzione di\n",
    "#  un termine di momento, che rappresenta l’accumulo di informazioni\n",
    "#  sulle iterazioni precedenti per guidare l’aggiornamento dei pesi. Il mo\n",
    "# mento agisce come una sorta di “inerzia” che accelera l’ottimizzazione\n",
    "#  nella direzione in cui la discesa del gradiente è costante e rallenta\n",
    "#  quando la direzione cambia bruscamente.\n",
    "#  • Iperparametri di una rete neurale.– Gli iperparametri sono parametri esterni al modello di machine learn\n",
    "# ing che devono essere impostati prima dell’avvio del processo di ad\n",
    "# destramento. A differenza dei parametri del modello, che vengono\n",
    "#  appresi durante il processo di addestramento stesso, gli iperparametri\n",
    "#  influenzano il comportamento del processo di addestramento e la con\n",
    "# 7\n",
    "# f\n",
    "#  igurazione del modello. Gli iperparametri devono essere scelti con\n",
    "#  cura, in quanto possono influenzare significativamente la qualità della\n",
    "#  soluzione ottenuta e la velocità di convergenza del processo di adde\n",
    "# stramento. Gli iperparametri di un modello di rete neurale includono:- numero di epoche di addestramento;- dimensione del batch di ad\n",
    "# destramento;- learning rate;- funzione di costo;- architettura della\n",
    "#  rete neurale (numero di layer, numero di neuroni per layer, tipo di\n",
    "#  layer);- funzione di attivazione dei neuroni;- regolarizzazione (early\n",
    "#  stopping, dropout, L1, L2);- ottimizzatore (Gradient Descent, SGD,\n",
    "#  Adam, Adagrad, RMSProp);- ecc.\n",
    "#  • learning rate scheduling: step decay, decadimento esponenziale, decadi\n",
    "# mento dipendente dal tempo.– Durante l’allenamento di un modello di machine learning, la\n",
    "#  regolazione del learning rate, o tasso di apprendimento, è spesso\n",
    "#  altrettanto importante della scelta dell’ottimizzatore. La selezione\n",
    "#  adeguata del learning rate può influire sulla velocità e sulla qual\n",
    "# ità della convergenza dell’algoritmo di ottimizzazione. All’inizio\n",
    "#  dell’allenamento, un learning rate elevato è auspicabile poiché i pesi\n",
    "#  del modello sono lontani dai minimi. Un learning rate alto consente\n",
    "#  un rapido aggiornamento dei pesi, accelerando l’apprendimento\n",
    "#  iniziale.\n",
    "#  Tuttavia, nella fase finale dell’apprendimento, quando\n",
    "#  i pesi si avvicinano ai minimi, un learning rate basso è più ap\n",
    "# propriato. Riducendo gradualmente il learning rate, si aumenta\n",
    "#  la probabilità di raggiungere il minimo globale senza oscillazioni\n",
    "#  eccessive. La regolazione del learning rate richiede la considerazione\n",
    "#  di diversi aspetti. In primo luogo, è importante selezionare una\n",
    "#  dimensione adeguata per il learning rate. Se il learning rate è troppo\n",
    "#  grande, l’ottimizzazione può divergere, mentre se è troppo piccolo,\n",
    "#  l’allenamento richiederà molto tempo o si otterrà un risultato subot\n",
    "# timale. Inoltre, è importante considerare il tasso di decadimento del\n",
    "#  learning rate nel corso dell’allenamento. Se il learning rate rimane\n",
    "#  elevato per troppo tempo, si può rimbalzare intorno al minimo\n",
    "#  senza raggiungerlo. Un decadimento graduale del learning rate può\n",
    "#  essere vantaggioso per raggiungere un compromesso tra la velocità\n",
    "#  di convergenza e la precisione del risultato finale.\n",
    "#  • Learning rate adattivo: Adagrad, RMSProp, Adadelta, Adam.– La regolazione del learning rate è una sfida nell’ottimizzazione dei\n",
    "#  modelli di machine learning, poiché gli iperparametri devono essere\n",
    "#  definiti in anticipo e dipendono dal tipo di modello e problema. In\n",
    "# oltre, applicare lo stesso learning rate a tutti gli aggiornamenti dei\n",
    "#  pesi potrebbe non essere ottimale, specialmente quando si hanno dati\n",
    "#  sparsi e si desidera aggiornare i pesi in modo diverso. Per affrontare\n",
    "#  queste sfide, sono stati sviluppati quattro metodi rappresentativi che\n",
    "#  modificano in modo adattivo il learning rate:\n",
    "#  ∗ Adagrad: Adagrad adatta il learning rate per ogni parametro\n",
    "#  del modello in base alla frequenza degli aggiornamenti prece\n",
    "# 8\n",
    "# denti. Ciò significa che i parametri che vengono aggiornati più fre\n",
    "# quentemente hanno un learning rate ridotto, mentre i parametri\n",
    "#  meno frequentemente aggiornati hanno un learning rate mag\n",
    "# giore. Questo approccio aiuta a gestire i problemi di sparsity\n",
    "#  dei dati.\n",
    "#  ∗ RMSProp: RMSProp(RootMeanSquarePropagation) modifica\n",
    "#  il learning rate in base alla media mobile degli aggiornamenti\n",
    "#  precedenti dei gradienti. Questo metodo attenua l’impatto dei\n",
    "#  gradienti di grandi dimensioni, consentendo una regolazione più\n",
    "#  stabile del learning rate nel corso dell’allenamento.\n",
    "#  ∗ Adadelta: Adadelta è un’altra tecnica che adatta il learning rate\n",
    "#  in base alla media mobile degli aggiornamenti dei gradienti prece\n",
    "# denti. Tuttavia, a differenza di RMSProp, Adadelta utilizza an\n",
    "# che una stima della varianza dei gradienti per regolare il learning\n",
    "#  rate. Questo approccio permette un aggiornamento più stabile\n",
    "#  dei pesi nel corso dell’allenamento.\n",
    "#  ∗ Adam: Adam (Adaptive Moment Estimation) combina le carat\n",
    "# teristiche di Adagrad e RMSProp. Utilizza la media mobile dei\n",
    "#  gradienti e la varianza per adattare il learning rate. Inoltre, in\n",
    "# corpora un termine di momento che tiene conto della storia degli\n",
    "#  aggiornamenti precedenti dei gradienti. Adam è uno dei metodi\n",
    "#  più utilizzati in pratica ed è efficace in una vasta gamma di prob\n",
    "# lemi.\n",
    "#  • Altro– Il vantaggio di jacobi è che si può parallelizzare. Ma nel caso non si\n",
    "#  parallelizza risulta essere più lento di gauss seidel\n",
    "#  9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
